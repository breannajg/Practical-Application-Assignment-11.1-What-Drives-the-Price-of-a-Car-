{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a regression analysis to model the relationship between the price of used cars (dependent variable) and a variety of features such as make, model, year, mileage, condition, fuel type, and other relevant characteristics (independent variables). The objective is to identify which factors significantly influence the price of used cars, and use this model to make data-driven recommendations to the client, a used car dealership, to optimize their pricing strategy.\n",
    "\n",
    "##### Key Components:\n",
    "\n",
    "Target Variable: Used car price (continuous)\n",
    "Predictor Variables: Vehicle characteristics including but not limited to:\n",
    "\n",
    "Categorical: make, model, fuel type, transmission, condition\n",
    "Numerical: year, mileage, engine size, horsepower\n",
    "\n",
    "\n",
    "\n",
    "##### Methodology:\n",
    "\n",
    "Conduct exploratory data analysis to identify patterns, distributions, and potential multicollinearity among predictor variables. <br>\n",
    "Perform feature engineering and selection to optimize model input. <br>\n",
    "Implement and compare multiple regression techniques (e.g., OLS, Ridge, Lasso, Random Forest) to capture both linear and non-linear relationships. <br>\n",
    "Evaluate model performance using metrics such as R-squared, RMSE, and MAE. <br>\n",
    "Analyze feature importance and coefficient estimates to determine the most influential factors on price. <br>\n",
    "Validate the model using cross-validation techniques to ensure generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me start by loading and inspecting the dataset to identify key features and their relationships to price.  I'll clean the dataset by handling missing values and identify which features are most likely to affect price. <br> It looked like many of these columns have a substantial amount of missing data, so I'll focus on columns with lower missing values and potentially relevant features. I'll proceed by removing rows with missing target values, fill or drop columns with significant missing values, and assess their impact on price. Let's start by cleaning the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            426880 non-null  int64  \n",
      " 1   region        426880 non-null  object \n",
      " 2   price         426880 non-null  int64  \n",
      " 3   year          425675 non-null  float64\n",
      " 4   manufacturer  409234 non-null  object \n",
      " 5   model         421603 non-null  object \n",
      " 6   condition     252776 non-null  object \n",
      " 7   cylinders     249202 non-null  object \n",
      " 8   fuel          423867 non-null  object \n",
      " 9   odometer      422480 non-null  float64\n",
      " 10  title_status  418638 non-null  object \n",
      " 11  transmission  424324 non-null  object \n",
      " 12  VIN           265838 non-null  object \n",
      " 13  drive         296313 non-null  object \n",
      " 14  size          120519 non-null  object \n",
      " 15  type          334022 non-null  object \n",
      " 16  paint_color   296677 non-null  object \n",
      " 17  state         426880 non-null  object \n",
      "dtypes: float64(2), int64(2), object(14)\n",
      "memory usage: 58.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           id                  region  price  year manufacturer model  \\\n",
       " 0  7222695916                prescott   6000   NaN          NaN   NaN   \n",
       " 1  7218891961            fayetteville  11900   NaN          NaN   NaN   \n",
       " 2  7221797935            florida keys  21000   NaN          NaN   NaN   \n",
       " 3  7222270760  worcester / central MA   1500   NaN          NaN   NaN   \n",
       " 4  7210384030              greensboro   4900   NaN          NaN   NaN   \n",
       " \n",
       "   condition cylinders fuel  odometer title_status transmission  VIN drive  \\\n",
       " 0       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       " 1       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       " 2       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       " 3       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       " 4       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       " \n",
       "   size type paint_color state  \n",
       " 0  NaN  NaN         NaN    az  \n",
       " 1  NaN  NaN         NaN    ar  \n",
       " 2  NaN  NaN         NaN    fl  \n",
       " 3  NaN  NaN         NaN    ma  \n",
       " 4  NaN  NaN         NaN    nc  ,\n",
       " None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset LOCALLY to inspect it\n",
    "df = pd.read_csv(r'C:\\Users\\brean\\Documents\\BerkAIML\\vehicles.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head(), df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size            71.767476\n",
       "cylinders       41.622470\n",
       "condition       40.785232\n",
       "VIN             37.725356\n",
       "drive           30.586347\n",
       "paint_color     30.501078\n",
       "type            21.752717\n",
       "manufacturer     4.133714\n",
       "title_status     1.930753\n",
       "model            1.236179\n",
       "odometer         1.030735\n",
       "fuel             0.705819\n",
       "transmission     0.598763\n",
       "year             0.282281\n",
       "id               0.000000\n",
       "region           0.000000\n",
       "price            0.000000\n",
       "state            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentage of missing values in each column\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "\n",
    "# Display columns with missing values sorted by percentage\n",
    "missing_percentage.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values and irrelevant columns\n",
    "df_cleaned = df.drop(columns=['id', 'region', 'state', 'VIN', 'size']).dropna(subset=['price', 'year', 'odometer'])\n",
    "\n",
    "# Feature Engineering (car age)\n",
    "current_year = datetime.datetime.now().year\n",
    "df_cleaned['car_age'] = current_year - df_cleaned['year']\n",
    "\n",
    "# Binning the odometer readings\n",
    "df_cleaned['odometer_bin'] = pd.cut(df_cleaned['odometer'], bins=[0, 50000, 100000, 150000, 200000, 500000],\n",
    "                                    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Limit the number of categories by selecting only the top 10 most common categories for 'model'\n",
    "top_models = df_cleaned['model'].value_counts().nlargest(10).index\n",
    "df_cleaned['model'] = df_cleaned['model'].apply(lambda x: x if x in top_models else 'Other')\n",
    "\n",
    "# Encoding categorical variables including 'odometer_bin'\n",
    "df_encoded = pd.get_dummies(df_cleaned, columns=['manufacturer', 'fuel', 'transmission', 'condition', \n",
    "                                                 'cylinders', 'drive', 'type', 'paint_color', 'title_status', \n",
    "                                                 'odometer_bin'])\n",
    "\n",
    "# Apply label encoding for 'model' to reduce memory usage\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded['model'] = label_encoder.fit_transform(df_cleaned['model'])\n",
    "\n",
    "# Log transformation for price to handle skewness  \n",
    "df_encoded['log_price'] = np.log(df_encoded['price'] + 1)\n",
    "\n",
    "# Scaling numeric features (like odometer and car_age)\n",
    "scaler = StandardScaler()\n",
    "df_encoded[['odometer', 'car_age']] = scaler.fit_transform(df_encoded[['odometer', 'car_age']])\n",
    "\n",
    "# Fill missing values\n",
    "# 1. Numeric columns: Fill with median\n",
    "numeric_columns = df_encoded.select_dtypes(include=[np.number]).columns\n",
    "df_encoded[numeric_columns] = df_encoded[numeric_columns].fillna(df_encoded[numeric_columns].median())\n",
    "\n",
    "# 2. Categorical columns: Fill with mode\n",
    "categorical_columns = df_encoded.select_dtypes(exclude=[np.number]).columns\n",
    "df_encoded[categorical_columns] = df_encoded[categorical_columns].fillna(df_encoded[categorical_columns].mode().iloc[0])\n",
    "\n",
    "# Splitting the data into features and target variable\n",
    "X = df_encoded.drop(columns=['price', 'log_price'])  # Exclude price from features\n",
    "y = df_encoded['log_price']  # Using log-transformed price\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "linear_reg = LinearRegression()\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Cross-validation for Linear Regression\n",
    "linear_cv_scores = cross_val_score(linear_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "linear_cv_mse = -linear_cv_scores.mean()\n",
    "\n",
    "# Fit the Linear Regression model\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred_linear = linear_reg.predict(X_test)\n",
    "linear_test_mse = mean_squared_error(y_test, y_pred_linear)\n",
    "\n",
    "# Cross-validation for Random Forest\n",
    "rf_cv_scores = cross_val_score(random_forest, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "rf_cv_mse = -rf_cv_scores.mean()\n",
    "\n",
    "# Fit the Random Forest model\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "rf_test_mse = mean_squared_error(y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The results\n",
    "print(\"Linear Regression CV MSE:\", linear_cv_mse)\n",
    "print(\"Linear Regression Test MSE:\", linear_test_mse)\n",
    "print(\"\\nRandom Forest CV MSE:\", rf_cv_mse)\n",
    "print(\"Random Forest Test MSE:\", rf_test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models, particularly the random forest, reveal key drivers of used car prices like car age, odometer reading, and manufacturer. However, the MSE indicates room for improvement, suggesting that non-linear relationships are important. While we offer valuable insights on significant price determinants, such as the impact of specific manufacturers and vehicle conditions, the modelsâ€™ accuracy may not fully meet our business objective.\n",
    "\n",
    "To enhance predictions, revisiting earlier phases, especially in feature engineering and data cleaning, is advisable. Incorporating additional data or refining categorical encodings could strengthen our models, ultimately providing more actionable insights for the client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Introduction\n",
    "This report presents an analysis of the key factors influencing used car prices, aimed at helping used car dealers optimize their inventory pricing strategies. We employed linear regression and random forest models to identify the primary drivers of car prices and provide actionable insights.\n",
    "\n",
    "##### 2. Data Overview\n",
    "We analyzed a dataset containing various attributes of used cars, including car age, odometer readings, manufacturer, model, transmission type, and condition. The dataset underwent rigorous cleaning and feature engineering to ensure the accuracy and relevance of our findings.\n",
    "\n",
    "##### 3. Key Findings\n",
    "Primary Price Drivers:\n",
    "\n",
    "Car Age: Older vehicles generally command lower prices, with depreciation accelerating significantly after the first few years.<br>\n",
    "Odometer Reading: Higher mileage is strongly associated with lower prices, reflecting the wear and tear on the vehicle.<br>\n",
    "Manufacturer: Certain manufacturers, such as Toyota and Honda, consistently command higher prices due to brand reputation for reliability and durability.<br>\n",
    "Condition and Transmission: Cars in better condition and with automatic transmissions tend to sell at higher prices. <br>\n",
    "Model Performance:<br>\n",
    "\n",
    "The random forest model outperformed the linear regression model, indicating that non-linear relationships and interactions between variables are crucial in accurately predicting car prices. <br>\n",
    "\n",
    "##### 4. Business Insights\n",
    "The analysis confirms that car age, mileage, and brand are critical in determining prices. Dealers should focus on acquiring and promoting vehicles with lower mileage, from reputable manufacturers, and in good condition to maximize profits.\n",
    "\n",
    "##### 5. Recommendations\n",
    "Inventory Selection: Prioritize vehicles with lower mileage and from manufacturers known for reliability.\n",
    "Pricing Strategy: Adjust prices based on vehicle age and condition, leveraging insights from the model to fine-tune pricing more precisely.\n",
    "Further Analysis: Consider incorporating additional data, such as market trends or regional demand, to further enhance pricing strategies.\n",
    "##### 6. Conclusion\n",
    "Our findings provide valuable insights that can help used car dealers optimize their inventory pricing. By focusing on the identified key drivers, dealers can improve their profitability and better meet market demands. Further refinement of the models, including additional data and more advanced techniques, could offer even greater precision in pricing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
